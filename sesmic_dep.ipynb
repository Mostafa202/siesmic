{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch._utils import classproperty\n",
    "import logging\n",
    "import logging.config\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.terminal.interactiveshell import TerminalInteractiveShell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"font.size\": 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from augmentations import*\n",
    "#from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet_unet import*\n",
    "import numpy as np\n",
    "import os, types \n",
    "import pandas as pd \n",
    "#from botocore.client import Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import Compose, HorizontalFlip, Normalize, PadIfNeeded, Resize\n",
    "from itkwidgets import view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from utilities import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data2 import*\n",
    "from data33 import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.contrib.handlers import CosineAnnealingScheduler,LinearCyclicalScheduler,ConcatScheduler\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from ignite.engine import Events\n",
    "from ignite.engine.engine import Engine\n",
    "from ignite.metrics import Loss\n",
    "from ignite.utils import convert_tensor\n",
    "from toolz import compose\n",
    "from torch.utils import data\n",
    "from batch import*\n",
    "from utils import *\n",
    "import  logging_handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import*\n",
    "#from dutchf3utils import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard_handlers import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine import*\n",
    "from metrics import *\n",
    "from itkwidgets import view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yacs.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE = (\n",
    "    \"seresnet_unet.yaml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of images to score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EVALUATE = 1\n",
    "# demo flag - by default notebook runs in demo mode and only fine-tunes the pre-trained model. Set to False for full re-training.\n",
    "DEMO = False\n",
    "# options are test1 or test2 - picks which Dutch F3 test set split to use\n",
    "TEST_SPLIT = \"test1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(N_EVALUATE, int) and N_EVALUATE>0, \"Number of images to score has to be a positive integer\"\n",
    "assert isinstance(DEMO, bool), \"demo mode should be a boolean\"\n",
    "assert TEST_SPLIT == \"test1\" or TEST_SPLIT == \"test2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CONFIG_FILE, \"rt\") as f_read:\n",
    "    config = yacs.config.load_cfg(f_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python test_sesmic.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_snapshots = config.TRAIN.SNAPSHOTS\n",
    "papermill = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = config.CUDNN.BENCHMARK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix random seeds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(config.SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(config.SEED)\n",
    "np.random.seed(seed=config.SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load a model<br>\n",
    "orch.cuda.set_enabled_lms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 'weights' as positional parameter(s) is deprecated since 0.13 and will be removed in 0.15. Please use keyword parameter(s) instead.\n",
      "Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n"
     ]
    }
   ],
   "source": [
    "model = get_seg_model(config)#model_f3_nb_resnet_unet_11124.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#model_f3_nb_resnet_unet_14832<br>\n",
    "#model_f3_nb_resnet_unet_14832.pt<br>\n",
    "#model_f3_nb_resnet_unet_14832.pt<br>\n",
    "#model_f3_nb_resnet_unet_24102.pt#model_f3_nb_resnet_unet_24102.pt<br>\n",
    "#model_f3_nb_resnet_unet_12978.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trained_model = torch.load(\"model_f3_nb_resnet_unet_12978.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trained_model = {k.replace(\"module.\", \"\"): v for (k, v) in trained_model.items()}<br>\n",
    "model.load_state_dict(trained_model, strict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your data file was loaded into a botocore.response.StreamingBody object.<br>\n",
    "Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.<br>\n",
    "ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/<br>\n",
    "pandas documentation: http://pandas.pydata.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send to GPU if available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send to GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD optimizer<br>\n",
    "optimizer = torch.optim.SGD(<br>\n",
    "    model.parameters(),<br>\n",
    "    lr=config.TRAIN.MAX_LR,<br>\n",
    "    momentum=config.TRAIN.MOMENTUM,<br>\n",
    "    weight_decay=config.TRAIN.WEIGHT_DECAY,<br>\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# learning rate scheduler<br>\n",
    "scheduler = CosineAnnealingScheduler(<br>\n",
    "    optimizer, \"lr\", config.TRAIN.MAX_LR, config.TRAIN.MIN_LR, cycle_size=snapshot_duration<br>\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# weights are inversely proportional to the frequency of the classes in the training set<br>\n",
    "class_weights = torch.tensor(<br>\n",
    "    config.DATASET.CLASS_WEIGHTS, device=device, requires_grad=False<br>\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss function<br>\n",
    "criterion = torch.nn.CrossEntropyLoss(<br>\n",
    "    weight=class_weights, ignore_index=255, reduction=\"mean\"<br>\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commented out IPython magic to ensure Python compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not papermill:\n",
    "     %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 9001 (pid 7865), started 3:38:32 ago. (Use '!kill 7865' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-88563a93d4b9cf7a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-88563a93d4b9cf7a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 9001;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not papermill:\n",
    "     %tensorboard --logdir $output_dir --port 9001 --host 0.0.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = torch.load(\"model_f3_nb_resnet_unet_25956_300epoch.pt\",map_location=torch.device('cpu'))\n",
    "trained_model = {k.replace(\"module.\", \"\"): v for (k, v) in trained_model.items()}\n",
    "model.load_state_dict(trained_model, strict=True)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmentation<br>\n",
    "augment entire sections with the same normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "section_aug = Compose(\n",
    "    [Normalize(mean=(config.TRAIN.MEAN,), std=(config.TRAIN.STD,), max_pixel_value=1,)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "augment each patch and not the entire sectiom which the patches are taken from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_aug = Compose(\n",
    "    [\n",
    "        Resize(\n",
    "            config.TRAIN.AUGMENTATIONS.RESIZE.HEIGHT,\n",
    "            config.TRAIN.AUGMENTATIONS.RESIZE.WIDTH,\n",
    "            always_apply=True,\n",
    "        ),\n",
    "        PadIfNeeded(\n",
    "            min_height=config.TRAIN.AUGMENTATIONS.PAD.HEIGHT,\n",
    "            min_width=config.TRAIN.AUGMENTATIONS.PAD.WIDTH,\n",
    "            border_mode=config.OPENCV_BORDER_CONSTANT,\n",
    "            always_apply=True,\n",
    "            #mask_value=255,\n",
    "            \n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processing = compose_processing_pipeline(config.TRAIN.DEPTH, aug=patch_aug)\n",
    "output_processing = output_processing_pipeline(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = TEST_SPLIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "abels = np.load(\"/content/test1_labels.npy\")<br>\n",
    "section_file = path.join(config.DATASET.ROOT, \"splits\", \"section_\" + split + \".txt\")<br>\n",
    "write_section_file(labels, section_file, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestSectionLoader = get_test_loader(config)\n",
    "test_set = TestSectionLoader(\n",
    "    config, split=split, is_transform=True, augmentations=section_aug\n",
    ")\n",
    "# needed to fix this bug in pytorch https://github.com/pytorch/pytorch/issues/973\n",
    "# one of the workers will quit prematurely\n",
    "torch.multiprocessing.set_sharing_strategy(\"file_system\")\n",
    "test_loader = data.DataLoader(\n",
    "    test_set, batch_size=1, num_workers=config.WORKERS, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = [\n",
    "    \"upper_ns\",\n",
    "    \"middle_ns\",\n",
    "    \"lower_ns\",\n",
    "    \"rijnland_chalk\",\n",
    "    \"scruff\",\n",
    "    \"zechstein\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keep only N_EVALUATE sections to score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subset = random.sample(list(test_loader), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list()\n",
    "running_metrics_split = runningScore(n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    # loop over testing data\n",
    "    for i, (images, labels) in enumerate(test_subset):\n",
    "        logger.info(f\"split: {split}, section: {i}\")\n",
    "        outputs = patch_label_2d(\n",
    "            model,\n",
    "            images,\n",
    "            pre_processing,\n",
    "            output_processing,\n",
    "            config.TRAIN.PATCH_SIZE,\n",
    "            config.TEST.TEST_STRIDE,\n",
    "            config.VALIDATION.BATCH_SIZE_PER_GPU,\n",
    "            device,\n",
    "            n_classes,\n",
    "        ) \n",
    "        pred = outputs.detach().max(1)[1].numpy()\n",
    "        gt = labels.numpy()\n",
    "        \n",
    "        # update evaluation metrics\n",
    "        running_metrics_split.update(gt, pred)\n",
    "        \n",
    "        # keep ground truth and result for plotting\n",
    "        results.append((np.squeeze(gt), np.squeeze(pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0][0][200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 50))\n",
    "# only plot a few images\n",
    "nplot = min(N_EVALUATE, 10)\n",
    "for idx in range(nplot):\n",
    "    # plot actual\n",
    "    plt.subplot(nplot, 2, 2 * (idx + 1) - 1)\n",
    "    plt.imshow(results[idx][0])\n",
    "    # plot predicted\n",
    "    plt.subplot(nplot, 2, 2 * (idx + 1))\n",
    "    plt.imshow(results[idx][1])\n",
    "    \n",
    "f_axes = fig.axes\n",
    "_ = f_axes[0].set_title(\"Actual\")\n",
    "_ = f_axes[1].set_title(\"Predicted\")\n",
    "fig.savefig(\"plot_predictions.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
