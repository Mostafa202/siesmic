{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57vOE0Xkh4-O",
        "outputId": "2bb0bf27-00c0-4ee9-c4a8-2aebff4e18eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.7/dist-packages (0.1.12)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.4.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from albumentations) (4.1.2.30)\n",
            "Requirement already satisfied: imgaug<0.2.7,>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.2.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (1.15.0)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (0.18.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (7.1.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (3.5.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.3.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.6.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2021.11.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (21.3)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.4.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (4.33.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "pip install albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JadhtDmsQAmS"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpKiKCqhh4-U",
        "outputId": "3920877f-f4fa-4809-c63e-98467d4530b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.7/dist-packages (3.1.27)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython) (4.0.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from gitpython) (4.1.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython) (5.0.0)\n"
          ]
        }
      ],
      "source": [
        "pip install gitpython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcoLqu6Oh4-Y",
        "outputId": "a6da8be8-0007-40d7-f6d1-48af93b24e49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch-ignite in /usr/local/lib/python3.7/dist-packages (0.4.9)\n",
            "Requirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.11.0+cu113)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytorch-ignite) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "pip install pytorch-ignite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTz2cwrMh4-a",
        "outputId": "c0c2f1f3-c693-4cdc-e06f-5a204dd6f14e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (2.5.1)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CS_xiXXnh4-c",
        "outputId": "8a50b051-9a40-4fa0-e4e1-0c4018ba9477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: itkwidgets in /usr/local/lib/python3.7/dist-packages (0.32.1)\n",
            "Requirement already satisfied: itk-filtering>=5.2.0.post2 in /usr/local/lib/python3.7/dist-packages (from itkwidgets) (5.2.1.post1)\n",
            "Requirement already satisfied: ipywidgets>=7.5.1 in /usr/local/lib/python3.7/dist-packages (from itkwidgets) (7.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from itkwidgets) (1.21.6)\n",
            "Requirement already satisfied: ipydatawidgets>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from itkwidgets) (4.3.1.post1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from itkwidgets) (3.5.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from itkwidgets) (1.15.0)\n",
            "Requirement already satisfied: colorcet in /usr/local/lib/python3.7/dist-packages (from itkwidgets) (3.0.0)\n",
            "Requirement already satisfied: itk-core>=5.2.0.post2 in /usr/local/lib/python3.7/dist-packages (from itkwidgets) (5.2.1.post1)\n",
            "Requirement already satisfied: itk-meshtopolydata>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from itkwidgets) (0.8.1)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.7/dist-packages (from itkwidgets) (0.18.0)\n",
            "Requirement already satisfied: ipympl>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from itkwidgets) (0.9.1)\n",
            "Requirement already satisfied: traittypes>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipydatawidgets>=4.0.1->itkwidgets) (0.2.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from ipympl>=0.4.1->itkwidgets) (7.1.2)\n",
            "Requirement already satisfied: ipython<9 in /usr/local/lib/python3.7/dist-packages (from ipympl>=0.4.1->itkwidgets) (5.5.0)\n",
            "Requirement already satisfied: traitlets<6 in /usr/local/lib/python3.7/dist-packages (from ipympl>=0.4.1->itkwidgets) (5.1.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from ipympl>=0.4.1->itkwidgets) (0.2.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython<9->ipympl>=0.4.1->itkwidgets) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython<9->ipympl>=0.4.1->itkwidgets) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython<9->ipympl>=0.4.1->itkwidgets) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython<9->ipympl>=0.4.1->itkwidgets) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython<9->ipympl>=0.4.1->itkwidgets) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython<9->ipympl>=0.4.1->itkwidgets) (57.4.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython<9->ipympl>=0.4.1->itkwidgets) (0.7.5)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5.1->itkwidgets) (5.4.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5.1->itkwidgets) (1.1.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5.1->itkwidgets) (4.10.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5.1->itkwidgets) (3.6.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->itkwidgets) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->itkwidgets) (5.1.1)\n",
            "Requirement already satisfied: itk-numerics==5.2.1.post1 in /usr/local/lib/python3.7/dist-packages (from itk-filtering>=5.2.0.post2->itkwidgets) (5.2.1.post1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib->itkwidgets) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->itkwidgets) (1.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->itkwidgets) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->itkwidgets) (0.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib->itkwidgets) (21.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib->itkwidgets) (4.33.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->itkwidgets) (4.1.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5.1->itkwidgets) (4.10.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5.1->itkwidgets) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5.1->itkwidgets) (2.15.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets>=7.5.1->itkwidgets) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets>=7.5.1->itkwidgets) (5.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets>=7.5.1->itkwidgets) (21.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets>=7.5.1->itkwidgets) (4.11.4)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat>=4.2.0->ipywidgets>=7.5.1->itkwidgets) (3.8.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython<9->ipympl>=0.4.1->itkwidgets) (0.2.5)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->itkwidgets) (5.3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->itkwidgets) (2.11.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->itkwidgets) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->itkwidgets) (0.13.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->itkwidgets) (1.8.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.5.1->itkwidgets) (23.1.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->itkwidgets) (0.7.0)\n",
            "Requirement already satisfied: param>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from colorcet->itkwidgets) (1.12.1)\n",
            "Requirement already satisfied: pyct>=0.4.4 in /usr/local/lib/python3.7/dist-packages (from colorcet->itkwidgets) (0.4.8)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->itkwidgets) (2.0.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->itkwidgets) (5.0.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->itkwidgets) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->itkwidgets) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->itkwidgets) (1.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->itkwidgets) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->itkwidgets) (0.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->itkwidgets) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "pip install itkwidgets "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtXIHFMNh4-e",
        "outputId": "b080b9eb-3e53-4cd4-fea9-81c2ba270d5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.7/dist-packages (0.1.8)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from yacs) (3.13)\n"
          ]
        }
      ],
      "source": [
        "pip install yacs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtSPODJih4-f",
        "outputId": "def3288e-3fc8-4978-b14a-d5971f2c5edb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Config in /usr/local/lib/python3.7/dist-packages (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "pip install Config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsOAWzi9h4-h",
        "outputId": "b7126806-34d3-4159-bf52-5a96b07d719a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: validators in /usr/local/lib/python3.7/dist-packages (0.20.0)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from validators) (4.4.2)\n"
          ]
        }
      ],
      "source": [
        "pip install validators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ijc1hFXpQE8k",
        "outputId": "f43f31b8-153c-4909-b4d9-38cdda8381bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "n_BuMhC3QFxF"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/gdrive/MyDrive/mop_azure')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otQV97HFh4-i"
      },
      "source": [
        "# Model training and evaluation on F3 Netherlands dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ja_RbNGr5sao"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBwWyC3zh4-n"
      },
      "source": [
        "In this notebook, we demonstrate how to train a deep neural network for facies prediction using the F3 Netherlands dataset. The F3 block is located in the North Sea off the shores of Netherlands. The dataset contains 6 classes (of lithostratigraphic units), all of which are of varying thickness (class imbalance). Processed data is available in numpy format as a `401 x 701 x 255` array. The processed F3 data is made publicly available by [Alaudah et al. 2019](https://github.com/yalaudah/facies_classification_benchmark).\n",
        "\n",
        "We specifically demonstrate a patch-based model approach, where we process a patch of an inline or crossline slice, instead of the entire slice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2vlbEHah4-p"
      },
      "source": [
        "## Environment setup\n",
        "\n",
        "To set up the conda environment and the Jupyter notebook kernel, please follow the instructions in the top-level [README.md](../../../README.md) file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2iXRehdh4-t"
      },
      "source": [
        "## Notebook-specific parameters\n",
        "\n",
        "Now let's set parameters which are required only for this notebook.\n",
        "\n",
        "We use configuration files to specify experiment configuration, such as hyperparameters used in training and evaluation, as well as other experiment settings. \n",
        "\n",
        "This notebook is designed to showcase the patch-based models on Dutch F3 dataset, hence we load the configuration files from that experiment by navigating to the `experiments` folder in the root directory. Each configuration file specifies a different Computer Vision model which is loaded for this notebook.\n",
        "\n",
        "Modify the `CONFIG_FILE` variable below if you would like to run the experiment using a different configuration file from the same experiment.\n",
        "\n",
        "For \"out-of-the-box\" Docker experience we, already pre-poppulated each model configuration file with the correct paramters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "pHeNIsF9h4-v"
      },
      "outputs": [],
      "source": [
        "\n",
        "#from botocore.client import Config \n",
        "\n",
        "# Your data file was loaded into a botocore.response.StreamingBody object.\n",
        "# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n",
        "# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n",
        "# pandas documentation: http://pandas.pydata.org/\n",
        "CONFIG_FILE = (\n",
        "    \"/content/gdrive/MyDrive/mop_azure/seresnet_unet.yaml\"\n",
        ")\n",
        "\n",
        "# number of images to score\n",
        "N_EVALUATE = 20\n",
        "# demo flag - by default notebook runs in demo mode and only fine-tunes the pre-trained model. Set to False for full re-training.\n",
        "DEMO = False\n",
        "# options are test1 or test2 - picks which Dutch F3 test set split to use\n",
        "TEST_SPLIT = \"test1\"\n",
        "\n",
        "\n",
        "# Your data file was loaded into a botocore.response.StreamingBody object.\n",
        "# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n",
        "# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n",
        "# pandas documentation: http://pandas.pydata.org/\n",
        "import os\n",
        "#assert os.path.isfile(CONFIG_FILE), \"Experiment config file CONFIG_FILE not found on disk\"\n",
        "assert isinstance(N_EVALUATE, int) and N_EVALUATE>0, \"Number of images to score has to be a positive integer\"\n",
        "assert isinstance(DEMO, bool), \"demo mode should be a boolean\"\n",
        "assert TEST_SPLIT == \"test1\" or TEST_SPLIT == \"test2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5udFAw-Vh4-v"
      },
      "outputs": [],
      "source": [
        "file1 = open('/content/gdrive/MyDrive/mop_azure/patch_train.txt', 'r')\n",
        "patch_train=file1.read()\n",
        "patch_train_list=patch_train.splitlines()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZBj82n-3q7qo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "dJYbAjluh4-x"
      },
      "outputs": [],
      "source": [
        "file1 = open('/content/gdrive/MyDrive/mop_azure/patch_val.txt', 'r')\n",
        "patch_val=file1.read()\n",
        "patch_val_list=patch_val.splitlines()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9TwS6aoh4-x"
      },
      "source": [
        "## Data download and preparation\n",
        "\n",
        "To download and prepare the F3 data set, please follow the instructions in the top-level [README](../../../README.md) file. Once you have downloaded and prepared the data set, you will find your files in the following directory tree:\n",
        "\n",
        "```\n",
        "data\n",
        "├── splits\n",
        "├── test_once\n",
        "│   ├── test1_labels.npy\n",
        "│   ├── test1_seismic.npy\n",
        "│   ├── test2_labels.npy\n",
        "│   └── test2_seismic.npy\n",
        "└── train\n",
        "    ├── train_labels.npy\n",
        "    └── train_seismic.npy\n",
        "```\n",
        "\n",
        "We recommend saving the data under `$HOME/data/dutchf3` since this notebook will use that location as the data root. Otherwise, modify the `DATASET.ROOT` field in the configuration file, described next. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR-ARJaSh4-x"
      },
      "source": [
        "\n",
        "## Library imports\n",
        "\n",
        "Let's load required libraries - the first step fixes the seeds to obtain reproducible results and the rest of the steps import the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "IzxNzqRHh4-y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import logging\n",
        "import logging.config\n",
        "from os import path\n",
        "\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams.update({\"font.size\": 16})\n",
        "\n",
        "from augmentations import*\n",
        "#from utilities import *\n",
        "\n",
        "import cv2\n",
        "\n",
        "from resnet_unet import*\n",
        "import numpy as np\n",
        "import os, types \n",
        "import pandas as pd \n",
        "#from botocore.client import Config \n",
        "\n",
        "from albumentations import Compose, HorizontalFlip, Normalize, PadIfNeeded, Resize\n",
        "from itkwidgets import view\n",
        "\n",
        "\n",
        "# Your data file was loaded into a botocore.response.StreamingBody object.\n",
        "# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n",
        "# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n",
        "# pandas documentation: http://pandas.pydata.org/\n",
        "import io\n",
        "from utilities import*\n",
        "\n",
        "from data2 import*\n",
        "from data33 import*\n",
        "\n",
        "from albumentations import Compose, HorizontalFlip, Normalize, PadIfNeeded, Resize\n",
        "from ignite.contrib.handlers import CosineAnnealingScheduler,LinearCyclicalScheduler,ConcatScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from ignite.engine import Events\n",
        "from ignite.engine.engine import Engine\n",
        "from ignite.metrics import Loss\n",
        "from ignite.utils import convert_tensor\n",
        "from toolz import compose\n",
        "from torch.utils import data\n",
        "from batch import*\n",
        "from utils import *\n",
        "import  logging_handlers\n",
        "\n",
        "\n",
        "from metrics import*\n",
        "#from dutchf3utils import*\n",
        "\n",
        "from tensorboard_handlers import*\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from engine import*\n",
        "from metrics import *\n",
        "from itkwidgets import view\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "    \n",
        "   \n",
        "   \n",
        "    \n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wCsunX4Th4-0"
      },
      "outputs": [],
      "source": [
        "import yacs.config\n",
        "with open(CONFIG_FILE, \"rt\") as f_read:\n",
        "    config = yacs.config.load_cfg(f_read)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T0MAxg8h4-0"
      },
      "source": [
        "We run test pipelines to test the notebooks, which use [papermill](https://papermill.readthedocs.io/en/latest/). If this notebook is being executed as part of such pipeline, the variables below are overridden. If not, we simply update these variable from a static configuration file specified earlier.\n",
        "\n",
        "Override parameters in case we use papermill:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "D7x3lV3uh4-1"
      },
      "outputs": [],
      "source": [
        "# The number of datapoints you want to run in training or validation per batch\n",
        "# Setting to None will run whole dataset\n",
        "# useful for integration tests with a setting of something like 3\n",
        "# Use only if you want to check things are running and don't want to run\n",
        "# through whole dataset\n",
        "# The number of epochs to run in training\n",
        "max_epochs = config.TRAIN.END_EPOCH\n",
        "max_snapshots = config.TRAIN.SNAPSHOTS\n",
        "papermill = False\n",
        "dataset_root = config.DATASET.ROOT\n",
        "model_pretrained = config.MODEL.PRETRAINED if \"PRETRAINED\" in config.MODEL.keys() else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MMzI3KFnh4-2"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "tyzTvJOVh4-3",
        "outputId": "0919360a-6681-4cba-e749-f7711e7500ed"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-8abb349957e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mworld_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'world_size' is not defined"
          ]
        }
      ],
      "source": [
        "world_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2g4gaLGh4-3"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TSFQqjRTh4-4"
      },
      "outputs": [],
      "source": [
        "# Fix random seeds, and set CUDNN benchmark mode:\n",
        "torch.backends.cudnn.benchmark = config.CUDNN.BENCHMARK\n",
        "\n",
        "# Fix random seeds:\n",
        "torch.manual_seed(config.SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(config.SEED)\n",
        "np.random.seed(seed=config.SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhqprkbEh4-4"
      },
      "source": [
        "For tests we reduce the number of data used by the Jupyter notebook (pending Ignite 0.3.0 where we can just reduce the number of batches per EPOCH)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "JhP5W5VXh4-2"
      },
      "outputs": [],
      "source": [
        "world_size = int(os.environ.get(\"WORLD_SIZE\", 4))\n",
        "distributed = world_size > 1\n",
        "\n",
        "\n",
        "#torch.cuda.set_device(4)\n",
        "\n",
        "# if distributed:\n",
        "#         # FOR DISTRIBUTED: Set the device according to local_rank.\n",
        "       \n",
        "\n",
        "#         #FOR DISTRIBUTED: Initialize the backend. torch.distributed.launch will\n",
        "#        #provide environment variables, and requires that you use init_method=`env://`.\n",
        "#        os.environ['MASTER_ADDR'] = 'notebook-f589825e1c364552ae536da887fe5f11-645cdb56cd-pd7zh'\n",
        "#        os.environ['MASTER_PORT'] = '33319'\n",
        "       \n",
        "#        torch.distributed.init_process_group(backend=\"nccl\",init_method=\"env://\",rank=4,world_size=world_size)\n",
        "        \n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0uC-7d0h4-4"
      },
      "source": [
        "## F3 data set "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XmPpO4lh4-5"
      },
      "source": [
        "Let's visualize a few sections of the F3 data set. The processed F3 data set is stored as a 3D numpy array. Let's view slices of the data along inline and crossline directions. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "k3Q0LuXhh4-5"
      },
      "outputs": [],
      "source": [
        "# Load training data and labels\n",
        "import numpy as np\n",
        "import os, types \n",
        "import pandas as pd \n",
        "#from botocore.client import Config \n",
        "\n",
        "from albumentations import Compose, HorizontalFlip, Normalize, PadIfNeeded, Resize\n",
        "from itkwidgets import view\n",
        "\n",
        "\n",
        "# Your data file was loaded into a botocore.response.StreamingBody object.\n",
        "# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n",
        "# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n",
        "# pandas documentation: http://pandas.pydata.org/\n",
        "import io\n",
        "from utilities import*\n",
        "\n",
        "from data2 import*\n",
        "from data33 import*\n",
        "\n",
        "\n",
        "\n",
        "# train_seismic = np.load(\"/content/gdrive/MyDrive/mop_azure/train_seismic.npy\")\n",
        "# train_labels = np.load(\"/content/gdrive/MyDrive/mop_azure/train_labels.npy\")\n",
        "\n",
        "# print(f\"Number of inline slices: {train_seismic.shape[0]}\")\n",
        "# print(f\"Number of crossline slices: {train_seismic.shape[1]}\")\n",
        "# print(f\"Depth dimension : {train_seismic.shape[2]}\")\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4r_Nr7Dah4-5"
      },
      "outputs": [],
      "source": [
        "# view(train_labels, slicing_planes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vlqeGoai6kws"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aC-e7YRXh4-6"
      },
      "source": [
        "Let's plot a __crossline__ slice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_anaJ7Bfh4-6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# idx = 100\n",
        "# x_in = train_seismic[idx, :, :].swapaxes(0, 1)\n",
        "# x_inl = train_labels[idx, :, :].swapaxes(0, 1)\n",
        "\n",
        "# plot_aline(x_in, x_inl, xlabel=\"crossline (relative)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhDBLcDrh4-7"
      },
      "source": [
        "Let's plot an __inline__ slice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "GRf1Q-3rh4-7"
      },
      "outputs": [],
      "source": [
        "# x_cr = train_seismic[:, idx, :].swapaxes(0, 1)\n",
        "# x_crl = train_labels[:, idx, :].swapaxes(0, 1)\n",
        "\n",
        "# plot_aline(x_cr, x_crl, xlabel=\"inline (relative)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNqCjbruh4-7"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "IsSOVLlDh4-8"
      },
      "outputs": [],
      "source": [
        "# Set up logging\n",
        "# load_log_configuration(config.LOG_CONFIG)\n",
        "# logger = logging.getLogger(__name__)\n",
        "# logger.debug(config.WORKERS)\n",
        "\n",
        "scheduler_step = config.TRAIN.END_EPOCH // config.TRAIN.SNAPSHOTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp10SXx6h4-8"
      },
      "source": [
        "### Set up data augmentation\n",
        "\n",
        "Let's define our data augmentation pipeline, which includes basic transformations, such as _data normalization, resizing, and padding_ if necessary. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "XznQTqpSh4-9"
      },
      "outputs": [],
      "source": [
        "# Setup Augmentations\n",
        "base_aug = Compose(\n",
        "    [\n",
        "        Normalize(\n",
        "            mean=(config.TRAIN.MEAN,), std=(config.TRAIN.STD,), max_pixel_value=1\n",
        "        ),\n",
        "        PadIfNeeded(\n",
        "            min_height=config.TRAIN.PATCH_SIZE,\n",
        "            min_width=config.TRAIN.PATCH_SIZE,\n",
        "            border_mode=0,\n",
        "            always_apply=True,\n",
        "            #mask_value=255,\n",
        "            value=0,\n",
        "        ),\n",
        "        Resize(\n",
        "            config.TRAIN.AUGMENTATIONS.RESIZE.HEIGHT,\n",
        "            config.TRAIN.AUGMENTATIONS.RESIZE.WIDTH,\n",
        "            always_apply=True,\n",
        "        ),\n",
        "        PadIfNeeded(\n",
        "            min_height=config.TRAIN.AUGMENTATIONS.PAD.HEIGHT,\n",
        "            min_width=config.TRAIN.AUGMENTATIONS.PAD.WIDTH,\n",
        "            border_mode=config.OPENCV_BORDER_CONSTANT,\n",
        "            always_apply=True,\n",
        "           # mask_value=255,\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "if config.TRAIN.AUGMENTATION:\n",
        "    train_aug = Compose([base_aug, HorizontalFlip(p=0.5)])\n",
        "    val_aug = base_aug\n",
        "else:\n",
        "    raise NotImplementedError(\n",
        "        \"We don't support turning off data augmentation at this time\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohrMf_OCh4--"
      },
      "source": [
        "### Load the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIwJyxLKh4--"
      },
      "source": [
        "For training the model, we will use a patch-based approach. Rather than using entire sections (crosslines or inlines) of the data, we extract a large number of small patches from the sections, and use the patches as our data. This allows us to generate larger set of images for training, but is also a more feasible approach for large seismic volumes. \n",
        "\n",
        "We are using a custom patch data loader from our __`deepseismic_interpretation`__ library for generating and loading patches from seismic section data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "K98iG7IEh4--"
      },
      "outputs": [],
      "source": [
        "# from torch.utils import data\n",
        "# scheduler_step = config.TRAIN.END_EPOCH // config.TRAIN.SNAPSHOTS\n",
        "\n",
        "# TrainPatchLoader = get_patch_loader(config)\n",
        "\n",
        "# train_set = TrainPatchLoader(\n",
        "#     config,\n",
        "#     train_seismic,\n",
        "#     train_labels,\n",
        "#     patch_train_list,\n",
        "    \n",
        "#     \"train\",\n",
        "#    True,\n",
        "#     # train_aug,\n",
        "# )\n",
        "# n_classes = train_set.n_classes\n",
        "# logger.info(train_set)\n",
        "# val_set = TrainPatchLoader(\n",
        "#     config,\n",
        "#     train_seismic,\n",
        "#     train_labels,\n",
        "#     patch_val_list,\n",
        "#     split=\"val\",\n",
        "#     is_transform=True,\n",
        "#     augmentations=val_aug,\n",
        "# )\n",
        "\n",
        "# if papermill:\n",
        "#     train_set = data.Subset(train_set, range(3))\n",
        "#     val_set = data.Subset(val_set, range(3))\n",
        "# elif DEMO:\n",
        "#     val_set = data.Subset(val_set, range(config.VALIDATION.BATCH_SIZE_PER_GPU))\n",
        "\n",
        "# #logger.info(val_set)\n",
        "\n",
        "# train_loader = data.DataLoader(\n",
        "#     train_set,\n",
        "#     batch_size=config.TRAIN.BATCH_SIZE_PER_GPU,\n",
        "#     num_workers=config.WORKERS,\n",
        "#     shuffle=True,\n",
        "# )\n",
        "# val_loader = data.DataLoader(\n",
        "#     val_set,\n",
        "#     batch_size=config.VALIDATION.BATCH_SIZE_PER_GPU,\n",
        "#     num_workers=config.WORKERS,\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TszErTXih4-_"
      },
      "source": [
        "\n",
        "streaming_body_20 = client_3143283556fa48bba0f75447c5588c58.get_object(Bucket='test-donotdelete-pr-bjfmmflhq2ln1r', Key='data2.py')['Body']\n",
        "\n",
        "# Your data file was loaded into a botocore.response.StreamingBody object.\n",
        "# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n",
        "# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n",
        "# pandas documentation: http://pandas.pydata.org/\n",
        "The following code defines the snapshot duration in batches over which we snapshot training models to disk. Variable `scheduler_step` defines how many epochs we have in a snapshot and multiplying that by the number of data points per epoch gives us the number of datapoints which we have per snapshot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "6UPkvHYph4_A"
      },
      "outputs": [],
      "source": [
        "# # if we're running in test mode, just run 2 batches\n",
        "# if papermill:\n",
        "#     train_len = 2\n",
        "# # if we're running in demo mode, just run 20 batches to fine-tune the model\n",
        "# elif DEMO:\n",
        "#     train_len = 20\n",
        "# # if we're not in test or demo modes, run the entire loop\n",
        "# else:\n",
        "#     train_len = len(train_loader)\n",
        "\n",
        "# snapshot_duration = scheduler_step * train_len if not papermill else train_len"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4jSpt6Uh4_A"
      },
      "source": [
        "We also must specify a batch transformation function which allows us to selectively manipulate the data for each batch into the format which model training expects in the next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "vPxj_wkyh4_B"
      },
      "outputs": [],
      "source": [
        "def prepare_batch(batch, device=None, non_blocking=False):\n",
        "    x, y = batch\n",
        "    return (\n",
        "        convert_tensor(x, device=device, non_blocking=non_blocking),\n",
        "        convert_tensor(y, device=device, non_blocking=non_blocking),\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj9uIqC4h4_B"
      },
      "source": [
        "### Set up model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DQA07Ith4_B"
      },
      "source": [
        "Next, let's define a model to train, an optimization algorithm, and a loss function. \n",
        "\n",
        "Note that the model is loaded from our __`cv_lib`__ library, using the name of the model as specified in the configuration file. To load a different model, either change the `MODEL.NAME` field in the configuration file, or create a new one corresponding to the model you wish to train."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "cj4wYDZrh4_C"
      },
      "outputs": [],
      "source": [
        "# load a model\n",
        "#torch.cuda.set_enabled_lms(True)\n",
        "model = get_seg_model(config)#model_f3_nb_resnet_unet_11124.pt\n",
        "\n",
        "# #model_f3_nb_resnet_unet_14832\n",
        "# #model_f3_nb_resnet_unet_14832.pt\n",
        "# #model_f3_nb_resnet_unet_14832.pt\n",
        "# #model_f3_nb_resnet_unet_24102.pt#model_f3_nb_resnet_unet_24102.pt\n",
        "# #model_f3_nb_resnet_unet_12978.pt\n",
        "\n",
        "# trained_model = torch.load(\"/content/gdrive/MyDrive/mop_azure_nb/model_f3_nb_resnet_unet_12978.pt\")\n",
        "\n",
        "# #\n",
        "\n",
        "# trained_model = {k.replace(\"module.\", \"\"): v for (k, v) in trained_model.items()}\n",
        "# model.load_state_dict(trained_model, strict=True)\n",
        "\n",
        "# Your data file was loaded into a botocore.response.StreamingBody object.\n",
        "# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n",
        "# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n",
        "# pandas documentation: http://pandas.pydata.org/\n",
        "\n",
        "\n",
        "# Send to GPU if available\n",
        "\n",
        "# Send to GPU if available\n",
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "# model = model.to(device)\n",
        "\n",
        "# # SGD optimizer\n",
        "# optimizer = torch.optim.SGD(\n",
        "#     model.parameters(),\n",
        "#     lr=config.TRAIN.MAX_LR,\n",
        "#     momentum=config.TRAIN.MOMENTUM,\n",
        "#     weight_decay=config.TRAIN.WEIGHT_DECAY,\n",
        "# )\n",
        "\n",
        "# # learning rate scheduler\n",
        "# scheduler = CosineAnnealingScheduler(\n",
        "#     optimizer, \"lr\", config.TRAIN.MAX_LR, config.TRAIN.MIN_LR, cycle_size=snapshot_duration\n",
        "# )\n",
        "\n",
        "# # weights are inversely proportional to the frequency of the classes in the training set\n",
        "# class_weights = torch.tensor(\n",
        "#     config.DATASET.CLASS_WEIGHTS, device=device, requires_grad=False\n",
        "# )\n",
        "\n",
        "# # loss function\n",
        "# criterion = torch.nn.CrossEntropyLoss(\n",
        "#     weight=class_weights, ignore_index=255, reduction=\"mean\"\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "yWPf1_Nwh4_C"
      },
      "outputs": [],
      "source": [
        "\n",
        "# torch.cuda.current_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Zsw9J5-nh4_D"
      },
      "outputs": [],
      "source": [
        "# device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "NyPBp2iVh4_D"
      },
      "outputs": [],
      "source": [
        "# sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "# sock.bind(('0.0.0.0', 0))\n",
        "# print('listening on port:', sock.getsockname()[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "HIbN-Lech4_E"
      },
      "outputs": [],
      "source": [
        "# import psutil\n",
        "    \n",
        "# ram=psutil.virtual_memory().total\n",
        "# ram*=9.31*10**-10\n",
        "# print(ram)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z--SE6esh4_E"
      },
      "source": [
        "## Training the model\n",
        "\n",
        "We use [ignite](https://pytorch.org/ignite/index.html) framework to create training and validation loops in our codebase. Ignite provides an easy way to create compact training/validation loops without too much boilerplate code.\n",
        "\n",
        "In this notebook, we demonstrate the use of ignite on the training loop only. We create a training engine `trainer` that loops multiple times over the training dataset and updates model parameters. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "KyiO6PdEh4_E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "43f501db-1026-469c-b564-85967f4b16ea"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-7148b3ac290b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create training engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m trainer = create_supervised_trainer(\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepare_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"
          ]
        }
      ],
      "source": [
        "# create training engine\n",
        "trainer = create_supervised_trainer(\n",
        "    model, optimizer, criterion, prepare_batch, device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1sqrl6yh4_F"
      },
      "source": [
        "#### Logging\n",
        "\n",
        "We add various events to the trainer, using an event system, that allows us to interact with the engine on each step of the run, such as, when the trainer is started/completed, when the epoch is started/completed and so on. \n",
        "\n",
        "Over the next few cells, we use event handlers to add the following events to the training loop:\n",
        "- log training output\n",
        "- log and schedule learning rate and\n",
        "- periodically save model to disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxQ_B39Lh4_F"
      },
      "outputs": [],
      "source": [
        "# define and create main output directory \n",
        "output_dir = config.OUTPUT_DIR+\"_nb\"\n",
        "generate_path(output_dir)\n",
        "\n",
        "# define main summary writer which logs all model summaries\n",
        "#summary_writer = create_summary_writer(log_dir=path.join(output_dir, config.LOG_DIR))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNAFmftDh4_G"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zd1wq-kTh4_G"
      },
      "outputs": [],
      "source": [
        "# type(summary_writer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vW_7kfZHh4_H"
      },
      "source": [
        "Next we need to score the model on validation set as it's training. To do this we need to add helper functions to manipulate data into the required shape just as we've done to prepare each batch for training at the beginning of this notebook.\n",
        "\n",
        "We also set up evaluation metrics which we want to record on the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrzQ_kKlh4_H"
      },
      "outputs": [],
      "source": [
        "transform_fn = lambda output_dict: (output_dict[\"y_pred\"].squeeze(), output_dict[\"mask\"].squeeze())\n",
        "evaluator = create_supervised_evaluator(\n",
        "    model,\n",
        "    prepare_batch,\n",
        "    metrics={\n",
        "        \"nll\": Loss(criterion, output_transform=transform_fn),\n",
        "        \"pixacc\": pixelwise_accuracy(n_classes, output_transform=transform_fn, device=device),\n",
        "        \"cacc\": class_accuracy(n_classes, output_transform=transform_fn,device=device),\n",
        "        \"mca\": mean_class_accuracy(n_classes, output_transform=transform_fn,device=device),\n",
        "        \"ciou\": class_iou(n_classes, output_transform=transform_fn,device=device),\n",
        "        \"mIoU\": mean_iou(n_classes, output_transform=transform_fn,device=device),\n",
        "    },\n",
        "    device=device,\n",
        ")\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "\n",
        "# Logging:\n",
        "#trainer.add_event_handler(Events.ITERATION_COMPLETED, log_training_output(CONFIG_FILE['PRINT_FREQ']))\n",
        "#trainer.add_event_handler(Events.EPOCH_COMPLETED, log_lr(optimizer))\n",
        "\n",
        "# Tensorboard and Logging:\n",
        "\n",
        "#trainer.add_event_handler(Events.ITERATION_COMPLETED, log_model_output(\"Training/loss\", summary_writer))\n",
        "#trainer.add_event_handler(Events.ITERATION_COMPLETED, log_model_output(\"Validation/loss\", summary_writer))\n",
        "\n",
        "# add specific logger which also triggers printed metrics on test set\n",
        "# @trainer.on(Events.EPOCH_COMPLETED)\n",
        "# def log_training_results(engine):\n",
        "#     evaluator.run(train_loader)\n",
        "#     log_results(engine, evaluator, summary_writer, n_classes, stage=\"Training\")\n",
        "#     log_metrics(engine, evaluator, stage=\"Training\")\n",
        "\n",
        "# # add specific logger which also triggers printed metrics on validation set\n",
        "# @trainer.on(Events.EPOCH_COMPLETED)\n",
        "# def log_validation_results(engine):\n",
        "#     evaluator.run(val_loader)\n",
        "#     log_results(engine, evaluator, summary_writer, n_classes, stage=\"Validation\")\n",
        "#     log_metrics(engine, evaluator, stage=\"Validation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gc88fKY8h4_I"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoALFpfIh4_I"
      },
      "source": [
        "We also checkpoint models and snapshot them to disk with every training epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mdsg9Jahh4_I"
      },
      "outputs": [],
      "source": [
        "# add model checkpointing\n",
        "checkpoint_handler = ModelCheckpoint(\n",
        "   output_dir,\n",
        "    \"model_f3_nb\",\n",
        "    save_interval=1,\n",
        "    n_saved=1,\n",
        "    create_dir=True,\n",
        "    require_empty=False,\n",
        ")\n",
        "\n",
        "trainer.add_event_handler(\n",
        "    Events.EPOCH_COMPLETED, checkpoint_handler, {config.MODEL.NAME: model}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToLiR_D1h4_J"
      },
      "source": [
        "Start the training engine run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9O8ula5h4_J"
      },
      "outputs": [],
      "source": [
        "torch.cuda.device_count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaoR9ndIh4_J"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Kwr0OYonUTjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fU4NL2gth4_K"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--I9_fbeh4_K"
      },
      "outputs": [],
      "source": [
        "trainer.run(train_loader, max_epochs=config.TRAIN.END_EPOCH, epoch_length=train_len, seed = config.SEED)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nelJw-41qcnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nAdOk-qkF_jW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PN6YdZcSdYLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BpF5_R_vOAcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbqrIeG01Gqk"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YM47i3UfGrEj"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkWfK1CSh4_L"
      },
      "source": [
        "## Tensorboard\n",
        "Using tensorboard for monitoring runs can be quite enlightening. Just ensure that the appropriate port is open on the VM so you can access it. Below we have the command for running tensorboard in your notebook. You can as easily view it in a seperate browser window by pointing the browser to the appropriate location and port."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lg1YYbdvXkQQ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zv94ziQiXlGn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YklF0DEh4_L"
      },
      "outputs": [],
      "source": [
        "if not papermill:\n",
        "    %load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNiKFFf4h4_M"
      },
      "outputs": [],
      "source": [
        "if not papermill:\n",
        "    %tensorboard --logdir $output_dir --port 9001 --host 0.0.0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75YcZiAhh4_M"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eaEA15kh4_M"
      },
      "source": [
        "We will next evaluate the performance of the model by looking at how well it predicts facies labels on samples from the test set.\n",
        "\n",
        "We will use the following evaluation metrics:\n",
        "\n",
        "- Pixel Accuracy (PA)\n",
        "- Class Accuracy (CA)\n",
        "- Mean Class Accuracy (MCA)\n",
        "- Frequency Weighted intersection-over-union (FW IoU)\n",
        "- Mean IoU (MIoU)\n",
        "\n",
        "You have an option here to use either the pre-trained model which we provided for you or to use the model which we just fine-tuned in this notebook. By default, we use the fine-tuned model, but you can change that in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x91olFX-h4_N"
      },
      "outputs": [],
      "source": [
        "# use the model which we just fine-tuned\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "VX9Q8HL-h4_N"
      },
      "outputs": [],
      "source": [
        "trained_model = torch.load(\"/content/gdrive/MyDrive/mop_azure_nb/model_f3_nb_resnet_unet_25956_300epoch.pt\")\n",
        "trained_model = {k.replace(\"module.\", \"\"): v for (k, v) in trained_model.items()}\n",
        "model.load_state_dict(trained_model, strict=True)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RgsVYx9h4_O"
      },
      "source": [
        "Next we load the test data and define the augmentations on it. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "YXEcF-soh4_O"
      },
      "outputs": [],
      "source": [
        "# Augmentation\n",
        "# augment entire sections with the same normalization\n",
        "from torch.utils import data\n",
        "section_aug = Compose(\n",
        "    [Normalize(mean=(config.TRAIN.MEAN,), std=(config.TRAIN.STD,), max_pixel_value=1,)]\n",
        ")\n",
        "\n",
        "# augment each patch and not the entire sectiom which the patches are taken from\n",
        "patch_aug = Compose(\n",
        "    [\n",
        "        Resize(\n",
        "            config.TRAIN.AUGMENTATIONS.RESIZE.HEIGHT,\n",
        "            config.TRAIN.AUGMENTATIONS.RESIZE.WIDTH,\n",
        "            always_apply=True,\n",
        "        ),\n",
        "        PadIfNeeded(\n",
        "            min_height=config.TRAIN.AUGMENTATIONS.PAD.HEIGHT,\n",
        "            min_width=config.TRAIN.AUGMENTATIONS.PAD.WIDTH,\n",
        "            border_mode=config.OPENCV_BORDER_CONSTANT,\n",
        "            always_apply=True,\n",
        "            #mask_value=255,\n",
        "            \n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Process test data\n",
        "pre_processing = compose_processing_pipeline(config.TRAIN.DEPTH, aug=patch_aug)\n",
        "output_processing = output_processing_pipeline(config)\n",
        "\n",
        "# Select the test split\n",
        "split = TEST_SPLIT\n",
        "\n",
        "#labels = np.load(\"/content/test1_labels.npy\")\n",
        "# section_file = path.join(config.DATASET.ROOT, \"splits\", \"section_\" + split + \".txt\")\n",
        "# write_section_file(labels, section_file, config)\n",
        "\n",
        "# Load test data\n",
        "TestSectionLoader = get_test_loader(config)\n",
        "test_set = TestSectionLoader(\n",
        "    config, split=split, is_transform=True, augmentations=section_aug\n",
        ")\n",
        "# needed to fix this bug in pytorch https://github.com/pytorch/pytorch/issues/973\n",
        "# one of the workers will quit prematurely\n",
        "torch.multiprocessing.set_sharing_strategy(\"file_system\")\n",
        "test_loader = data.DataLoader(\n",
        "    test_set, batch_size=1, num_workers=config.WORKERS, shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvEPxHnxh4_P"
      },
      "source": [
        "### Predict segmentation mask on the test data\n",
        "\n",
        "For demonstration purposes and efficiency, we will only use a subset of the test data to predict segmentation mask on. More precisely, we will score `N_EVALUATE` images. If you would like to evaluate more images, set this variable to the desired number of images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "QEN8tuCUh4_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd90ed05-55de-402c-89ea-88a8ca417a8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n"
          ]
        }
      ],
      "source": [
        "CLASS_NAMES = [\n",
        "    \"upper_ns\",\n",
        "    \"middle_ns\",\n",
        "    \"lower_ns\",\n",
        "    \"rijnland_chalk\",\n",
        "    \"scruff\",\n",
        "    \"zechstein\",\n",
        "]\n",
        "\n",
        "n_classes = len(CLASS_NAMES)\n",
        "\n",
        "# keep only N_EVALUATE sections to score\n",
        "test_subset = random.sample(list(test_loader), 20)\n",
        "\n",
        "results = list()\n",
        "running_metrics_split = runningScore(n_classes)\n",
        "\n",
        "# testing mode\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    # loop over testing data\n",
        "    for i, (images, labels) in enumerate(test_subset):\n",
        "        logger.info(f\"split: {split}, section: {i}\")\n",
        "        outputs = patch_label_2d(\n",
        "            model,\n",
        "            images,\n",
        "            pre_processing,\n",
        "            output_processing,\n",
        "            config.TRAIN.PATCH_SIZE,\n",
        "            config.TEST.TEST_STRIDE,\n",
        "            config.VALIDATION.BATCH_SIZE_PER_GPU,\n",
        "            device,\n",
        "            n_classes,\n",
        "        )\n",
        "\n",
        "        pred = outputs.detach().max(1)[1].numpy()\n",
        "        gt = labels.numpy()\n",
        "        \n",
        "        # update evaluation metrics\n",
        "        running_metrics_split.update(gt, pred)\n",
        "        \n",
        "        # keep ground truth and result for plotting\n",
        "        results.append((np.squeeze(gt), np.squeeze(pred)))\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(list(test_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucL3XcxK31JF",
        "outputId": "df970621-ab3b-48ac-fbf8-f88a96d1b526"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "901"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSA3Kfi9h4_Q"
      },
      "source": [
        "Let's view the obtained metrics on this subset of test images. Note that we trained our model for for a small number of epochs, for demonstration purposes, so the performance results here are not meant to be representative. \n",
        "\n",
        "The performance exceed the ones shown here when the models are trained properly. For the full report on benchmarking performance results, please refer to the [README.md](../../../README.md) file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "_G4pNW7ah4_Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae77ff84-6190-4ef4-f236-9929cfd4facb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pixel Acc: 0.890\n",
            "  upper_ns_accuracy 0.993\n",
            "  middle_ns_accuracy 0.873\n",
            "  lower_ns_accuracy 0.980\n",
            "  rijnland_chalk_accuracy 0.901\n",
            "  scruff_accuracy 0.542\n",
            "  zechstein_accuracy 0.951\n",
            "Mean Class Acc: 0.873\n",
            "Freq Weighted IoU: 0.803\n",
            "Mean IoU: 0.754\n"
          ]
        }
      ],
      "source": [
        "# get scores\n",
        "score, _ = running_metrics_split.get_scores()\n",
        "\n",
        "# Log split results\n",
        "print(f'Pixel Acc: {score[\"Pixel Acc: \"]:.3f}')\n",
        "for cdx, class_name in enumerate(CLASS_NAMES):\n",
        "    print(f'  {class_name}_accuracy {score[\"Class Accuracy: \"][cdx]:.3f}')\n",
        "\n",
        "print(f'Mean Class Acc: {score[\"Mean Class Acc: \"]:.3f}')\n",
        "print(f'Freq Weighted IoU: {score[\"Freq Weighted IoU: \"]:.3f}')\n",
        "print(f'Mean IoU: {score[\"Mean IoU: \"]:0.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDkMZqzBh4_R"
      },
      "source": [
        "### Visualize predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE_a7JtTh4_R"
      },
      "source": [
        "Let's visualize the predictions on entire test sections. Note that the crosslines and inlines have different dimensions, however we were able to use them jointly for our network training and evaluation, since we were using smaller patches from the sections, whose size we can control via hyperparameter in the experiment configuration file. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kb6ZjEDFh4_R"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(15, 50))\n",
        "# only plot a few images\n",
        "nplot = min(N_EVALUATE, 10)\n",
        "for idx in range(nplot):\n",
        "    # plot actual\n",
        "    plt.subplot(nplot, 2, 2 * (idx + 1) - 1)\n",
        "    plt.imshow(results[idx][0])\n",
        "    # plot predicted\n",
        "    plt.subplot(nplot, 2, 2 * (idx + 1))\n",
        "    plt.imshow(results[idx][1])\n",
        "    \n",
        "f_axes = fig.axes\n",
        "_ = f_axes[0].set_title(\"Actual\")\n",
        "_ = f_axes[1].set_title(\"Predicted\")\n",
        "fig.savefig(\"plot_predictions.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIgh4QSYh4_R"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_rZ-tLzh4_R"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_oRoN95uh4_S"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4k-wx9Jbh4_a"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nS38KMvgh4_a"
      },
      "outputs": [],
      "source": [
        "#    C:\\Users\\username\\AppData\\Roaming\\IBM Watson Studio\\projects\\project-name\\assets\\notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_CSXrH5h4_b"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DiU28iIh4_b"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3H-2HEIVh4_b"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZ4Zf8Rih4_c"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwkDeaxih4_c"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYkXvW_Nh4_c"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eNJ7joNh4_e"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HiZv397O9t5o"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "n9TwS6aoh4-x",
        "vDkMZqzBh4_R"
      ],
      "name": "train_test.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}